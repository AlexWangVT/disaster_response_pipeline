{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jwang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jwang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jwang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /Users/jwang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/jwang/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger', 'stopwords', 'omw-1.4'])\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "category_df = pd.read_csv('disaster_categories.csv')\n",
    "message_df = pd.read_csv('disaster_messages.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-1;medi...</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>related-1;request-1;offer-0;aid_related-1;medi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         categories  \\\n",
       "0   2  related-1;request-0;offer-0;aid_related-0;medi...   \n",
       "1   7  related-1;request-0;offer-0;aid_related-1;medi...   \n",
       "2   8  related-1;request-0;offer-0;aid_related-0;medi...   \n",
       "3   9  related-1;request-1;offer-0;aid_related-1;medi...   \n",
       "4  12  related-1;request-0;offer-0;aid_related-0;medi...   \n",
       "\n",
       "                                             message  \\\n",
       "0  Weather update - a cold front from Cuba that c...   \n",
       "1            Is the Hurricane over or is it not over   \n",
       "2                    Looking for someone but no name   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  \n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct  \n",
       "1                 Cyclone nan fini osinon li pa fini  direct  \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct  \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct  \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge data\n",
    "merge_df = category_df.merge(message_df, how = 'inner', on = 'id')\n",
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 5)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate data\n",
    "merge_df = merge_df.drop_duplicates()\n",
    "merge_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-1;medi...</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>related-1;request-1;offer-0;aid_related-1;medi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>related-1;request-0;offer-0;aid_related-0;medi...</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         categories  \\\n",
       "0   2  related-1;request-0;offer-0;aid_related-0;medi...   \n",
       "1   7  related-1;request-0;offer-0;aid_related-1;medi...   \n",
       "2   8  related-1;request-0;offer-0;aid_related-0;medi...   \n",
       "3   9  related-1;request-1;offer-0;aid_related-1;medi...   \n",
       "4  12  related-1;request-0;offer-0;aid_related-0;medi...   \n",
       "\n",
       "                                             message  \n",
       "0  Weather update - a cold front from Cuba that c...  \n",
       "1            Is the Hurricane over or is it not over  \n",
       "2                    Looking for someone but no name  \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  \n",
       "4  says: west side of Haiti, rest of the country ...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop column which is not needed for modeling and has a bunch of missing values\n",
    "df = merge_df.drop(['original', 'genre'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization and Tokenization  \n",
    "df.message = [word_tokenize(re.sub(r\"[^a-zA-Z0-9]\", \" \", text).lower()) for text in df.message]\n",
    "df.categories = [word_tokenize(re.sub(r\"[^a-zA-Z0-9]\", \" \", text).lower()) for text in df.categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words and Lemmatization\n",
    "def lemmatize_stopwords_text(text):\n",
    "    return [WordNetLemmatizer().lemmatize(w, pos='v').strip() for w in text if w not in stopwords.words(\"english\")]\n",
    "\n",
    "df.categories = df.categories.apply(lemmatize_stopwords_text)\n",
    "df.message = df.message.apply(lemmatize_stopwords_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98800615, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.15441455, 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.84058946, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.13137494, 0.52549975, 0.        ],\n",
       "       [0.95630012, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.16304645, 0.        , 0.        , 0.24270545],\n",
       "       [0.90541816, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.42452086, 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.90918147, 0.23074691, 0.        , 0.        , 0.        ,\n",
       "        0.31002571, 0.        , 0.15501286, 0.        ],\n",
       "       [0.97360364, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.2282454 , 0.        , 0.        , 0.        ],\n",
       "       [0.86361568, 0.        , 0.        , 0.22961974, 0.22961974,\n",
       "        0.        , 0.30851128, 0.23138346, 0.        ],\n",
       "       [0.91937934, 0.        , 0.28518733, 0.        , 0.        ,\n",
       "        0.19158525, 0.        , 0.19158525, 0.        ]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of words and TF-IDF\n",
    "vectorizer = TfidfVectorizer(stop_words={'english'}, token_pattern=r\"[^a-zA-Z0-9]\")\n",
    "df_1 = vectorizer.fit_transform(df.message.loc[0:10]) \n",
    "# df['categories_tfidf'] = [transformer.fit_transform(vect.fit_transform(txt)) for txt in df.categories]\n",
    "df_1.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather', 'update', 'cold', 'front', 'cuba', 'could', 'pass', 'haiti']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.message.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8d1ef3b3d21a8f5d62fec297b2de45fe0670853a5f20151ae07585d912ea79d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
